{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-01T20:17:02.987820Z","iopub.execute_input":"2026-01-01T20:17:02.988191Z","iopub.status.idle":"2026-01-01T20:17:05.403030Z","shell.execute_reply.started":"2026-01-01T20:17:02.988169Z","shell.execute_reply":"2026-01-01T20:17:05.402014Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create the training dataframe using the path found above\ntrain_data = pd.read_csv('/kaggle/input/titanic/train.csv')\n\n# Look at the columns and first few rows\ntrain_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T20:18:25.368263Z","iopub.execute_input":"2026-01-01T20:18:25.368550Z","iopub.status.idle":"2026-01-01T20:18:25.417006Z","shell.execute_reply.started":"2026-01-01T20:18:25.368529Z","shell.execute_reply":"2026-01-01T20:18:25.416248Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T20:19:03.140187Z","iopub.execute_input":"2026-01-01T20:19:03.140789Z","iopub.status.idle":"2026-01-01T20:19:03.148574Z","shell.execute_reply.started":"2026-01-01T20:19:03.140737Z","shell.execute_reply":"2026-01-01T20:19:03.147793Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data.groupby('Sex')['Survived'].mean()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T20:19:30.399553Z","iopub.execute_input":"2026-01-01T20:19:30.400128Z","iopub.status.idle":"2026-01-01T20:19:30.418586Z","shell.execute_reply.started":"2026-01-01T20:19:30.400102Z","shell.execute_reply":"2026-01-01T20:19:30.417632Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.barplot(x='Pclass', y='Survived', data=train_data)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T20:19:50.577363Z","iopub.execute_input":"2026-01-01T20:19:50.578027Z","iopub.status.idle":"2026-01-01T20:19:51.857177Z","shell.execute_reply.started":"2026-01-01T20:19:50.578001Z","shell.execute_reply":"2026-01-01T20:19:51.856279Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a new version of the dataframe with specific columns removed\ntrain_data_cleaned = train_data.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n\n# View the result to confirm they are gone\ntrain_data_cleaned.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T20:21:32.480500Z","iopub.execute_input":"2026-01-01T20:21:32.481268Z","iopub.status.idle":"2026-01-01T20:21:32.495505Z","shell.execute_reply.started":"2026-01-01T20:21:32.481243Z","shell.execute_reply":"2026-01-01T20:21:32.494557Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fill missing Age with the median age\ntrain_data['Age'] = train_data['Age'].fillna(train_data['Age'].median())\n\n# Fill missing Embarked with the most common port ('S' for Southampton)\ntrain_data['Embarked'] = train_data['Embarked'].fillna('S')\n\n# Verify there are no more missing values\nprint(train_data.isnull().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T20:22:26.084882Z","iopub.execute_input":"2026-01-01T20:22:26.085200Z","iopub.status.idle":"2026-01-01T20:22:26.094968Z","shell.execute_reply.started":"2026-01-01T20:22:26.085176Z","shell.execute_reply":"2026-01-01T20:22:26.093986Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# We select only the columns we want to use as 'Features'\nfeatures = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n\n# Use pd.get_dummies to turn text into numbers automatically\nX = pd.get_dummies(train_data[features])\n\n# View the result - you'll see columns like 'Sex_male' now\nX.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T20:22:49.287311Z","iopub.execute_input":"2026-01-01T20:22:49.287636Z","iopub.status.idle":"2026-01-01T20:22:49.308811Z","shell.execute_reply.started":"2026-01-01T20:22:49.287612Z","shell.execute_reply":"2026-01-01T20:22:49.308047Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y = train_data[\"Survived\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T20:22:57.487717Z","iopub.execute_input":"2026-01-01T20:22:57.488082Z","iopub.status.idle":"2026-01-01T20:22:57.492577Z","shell.execute_reply.started":"2026-01-01T20:22:57.488058Z","shell.execute_reply":"2026-01-01T20:22:57.491705Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n# 1. Initialize the model\n# n_estimators = number of trees\n# max_depth = how \"deep\" each tree can grow (prevents memorizing noise)\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n\n# 2. Train the model (The \"Fit\" step)\n# This is where the model learns the relationship between X (features) and y (survival)\nmodel.fit(X, y)\n\nprint(\"Model Training Complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T20:23:52.171424Z","iopub.execute_input":"2026-01-01T20:23:52.172249Z","iopub.status.idle":"2026-01-01T20:23:53.184212Z","shell.execute_reply.started":"2026-01-01T20:23:52.172215Z","shell.execute_reply":"2026-01-01T20:23:53.183406Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1. Load test data\ntest_data = pd.read_csv('/kaggle/input/titanic/test.csv')\n\n# 2. Fill missing values (Age and Fare)\ntest_data['Age'] = test_data['Age'].fillna(test_data['Age'].median())\ntest_data['Fare'] = test_data['Fare'].fillna(test_data['Fare'].median())\ntest_data['Embarked'] = test_data['Embarked'].fillna('S')\n\n# 3. Select features and convert to numbers (One-Hot Encoding)\nX_test = pd.get_dummies(test_data[features])\n\n# Ensure X_test has the exact same columns as X\nX_test = X_test.reindex(columns = X.columns, fill_value=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T20:24:20.289271Z","iopub.execute_input":"2026-01-01T20:24:20.289660Z","iopub.status.idle":"2026-01-01T20:24:20.310945Z","shell.execute_reply.started":"2026-01-01T20:24:20.289628Z","shell.execute_reply":"2026-01-01T20:24:20.309844Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions = model.predict(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T20:24:34.569429Z","iopub.execute_input":"2026-01-01T20:24:34.570092Z","iopub.status.idle":"2026-01-01T20:24:34.587479Z","shell.execute_reply.started":"2026-01-01T20:24:34.570066Z","shell.execute_reply":"2026-01-01T20:24:34.586410Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T20:25:04.848136Z","iopub.execute_input":"2026-01-01T20:25:04.848538Z","iopub.status.idle":"2026-01-01T20:25:04.860453Z","shell.execute_reply.started":"2026-01-01T20:25:04.848510Z","shell.execute_reply":"2026-01-01T20:25:04.859610Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}